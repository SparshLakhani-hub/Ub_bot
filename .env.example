# LLM provider selection: "ollama" (default, local) or "openai"
LLM_PROVIDER=ollama

# Ollama configuration (used when LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_CHAT_MODEL=llama3.1
OLLAMA_EMBED_MODEL=nomic-embed-text

# OpenAI configuration (only used when LLM_PROVIDER=openai)
OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE
OPENAI_CHAT_MODEL=gpt-4.1-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# Paths (can be absolute or relative)
UB_DATA_DIR=./data/ub_pages
VECTOR_STORE_DIR=./vector_store/ub
UB_COLLECTION_NAME=ub_knowledge

# Conversation history (number of previous turns to keep)
MAX_HISTORY_TURNS=4
